\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi)
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text.
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{verbatim}
\usepackage{float}
\usepackage{tikz}
    \usetikzlibrary{shapes,arrows}
    \usetikzlibrary{arrows,calc,positioning}

    \tikzset{
        block/.style = {draw, rectangle,
            minimum height=1cm,
            minimum width=1.5cm},
        input/.style = {coordinate,node distance=1cm},
        output/.style = {coordinate,node distance=4cm},
        arrow/.style={draw, -latex,node distance=2cm},
        pinstyle/.style = {pin edge={latex-, black,node distance=2cm}},
        sum/.style = {draw, circle, node distance=1cm},
    }
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}

\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\newenvironment{problem}[2][Problem]
    { \begin{mdframed}[backgroundcolor=gray!20] \textbf{#1 #2} \\}
    {  \end{mdframed}}

% Define solution environment
\newenvironment{solution}
    {\textit{Solution:}}
    {}

\renewcommand{\qed}{\quad\qedsymbol}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%Header-Make sure you update this information!!!!
\noindent
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\large\textbf{xxxx} \hfill \textbf{Homeworkxx}   \\
Email: xxxx \hfill ID: 201900015x \\
\normalsize Course: Bayesian \hfill Term: Spring 2020\\
\noindent\rule{7in}{2.8pt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{3.1}
Binomial and multinomial models: suppose data $(y_1,\dots,y_J)$ follow a multinomial distribution with parameters $(\theta_1,\dots,\theta_J)$.
Also suppose that $\theta = (\theta_1,\dots,\theta_J)$ has a Dirichlet prior distribution.Let $\alpha =\frac{\theta_1}{\theta_1+\theta_2}$.

(a)Write the marginal posterior distribution for $\alpha$.

(b)Show that this distribution is identical to the posterior distribution for $\alpha$ obtained by treating $y_1$ as an observation from the binomial 
  distribution with probability $\alpha$ and sample size $y_1 + y_2$, ignoring the data $y_3,\dots,y_J$.

This result justifies the application of the binomial distribution to multinomial problems when we are only interested in two of the categories;
for example, see the next problem.
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{3.3}
  Estimation from two independent experiments: an experiment was performed on the effects of magnetic fields on the flow of calcium out of chicken 
  brains. Two groups of chickens were involved: a control group of 32 chickens and an exposed group of 36 chickens. 
  One measurement was taken on each chicken, and the purpose of the experiment was to measure the average flow $\mu_c$ in untreated (control) chickens 
  and the average flow $\mu_t$ in treated chickens. The 32 measurements on the control group had a sample mean of 1.013 and a sample 
  standard deviation of 0.24. The 36 measurements on the treatment group had a sample mean of 1.173 and a sample standard deviation of 0.20.

  (a)Assuming the control measurements were taken at random from a normal distribution with mean $\mu_c$ and variance 
  $\sigma_c^2$ , what is the posterior distribution of $\mu_c$? Similarly, use the treatment group measurements to determine the marginal posterior 
  distribution of $\mu_t$. Assume a uniform prior distribution on $(\mu_c, \mu_t, \log \sigma_c, \log \sigma_t)$.
  
  (b) What is the posterior distribution for the difference, $\mu_t-\mu_c$? To get this, you may sample from the independent $t$ 
  distributions you obtained in part (a) above. Plot a histogram of your samples and give an approximate 95\% posterior interval for $\mu_t-\mu_c$.
  
  The problem of estimating two normal means with unknown ratio of variances is called the Behrens–Fisher problem
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{3.6}
Binomial with unknown probability and sample size: some of the difficulties with setting prior distributions in multiparameter models can be 
illustrated with the simple binomial distribution. Consider data $y_1,\dots,y_n$ modeled as independent $Bin(N,\theta)$, with both $N$ and $\theta$ 
unknown. Defining a convenient family of prior distributions on $(N,\theta)$ is difficult, partly because of the discreteness of $N$.

Raftery (1988) considers a hierarchical approach based on assigning the parameter $N$ a Poisson distribution with \textit{unknown} mean $\mu$.
To define a prior distribution on $(\theta,N)$, Raftery defines $\lambda=\mu\theta$ and specifies a prior distribution on $(\lambda,\theta)$. 
The prior distribution is specified in terms of $\lambda$ rather than $\mu$ because ‘it would seem easier to formulate prior information 
about $\lambda$, the unconditional expectation of the observations, than about $\mu$, the mean of the unobserved quantity $N$.’

(a) A suggested noninformative prior distribution is $p(\lambda,\theta) \propto \lambda^{-1}$. What is a motivation for this noninformative distribution?
Is the distribution improper? Transform to determine $p(N,\theta)$.

(b) The Bayesian method is illustrated on counts of waterbuck obtained by remote photography on five separate days in Kruger Park in South Africa.
The counts were 53, 57, 66, 67, and 72. Perform the Bayesian analysis on these data and display a scatterplot of posterior simulations of $(N,\theta)$.
What is the posterior probability that $N>100$?

(c) Why not simply use a Poisson with fixed $\mu$ as a prior distribution for $N$?
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{problem}{3.9}
Conjugate normal model: suppose $y$ is an independent and identically distributed sample of size $n$ from the distribution $N(\mu, \sigma^2)$, 
where $(\mu, \sigma^2)$ have the N-Inv-$\chi^2(\mu_0, \sigma_0^2/\kappa_0;\nu_0,\sigma_0^2)$ prior distribution,(that is, 
$\sigma^2 \sim$ Inv-$\chi^2(\nu_0,\sigma_0^2)$ and $\mu|\sigma^2 \sim N(\mu_0.\sigma^2/\kappa_0)$).The posterior distribution,
$p(\mu, \sigma^2|y)$, is also normal-inverse-$\chi^2$; derive explicitly its parameters in terms of 
the prior parameters and the sufficient statistics of the data.
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{3.13}
Multivariate normal model: derive equations (3.13) by completing the square in vectormatrix notation.
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{3.15}
Joint distributions: The autoregressive time-series model $y_1, y_2,\dots$ with mean level 0, autocorrelation 0.8, residual standard deviation 
1, and normal errors can be written as $(y_t|y_{t-1},y_{t-2},\dots) \sim N(0.8y_{t-1}, 1)$ for all $t$.

(a) Prove that the distribution of $y_t$, given the observations at all other integer time points $t$, depends only on $y_{t-1}$ and $y_{t+1}$.

(b) What is the distribution of $y_t$ given $y_{t-1}$ and $y_{t+1}$.
\end{problem}
\begin{solution}

\end{solution}

\noindent\rule{7in}{2.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
