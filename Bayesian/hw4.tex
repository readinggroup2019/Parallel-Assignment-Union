\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text. 
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{verbatim}
\usepackage[numbered]{mcode}
\usepackage{float}
\usepackage{tikz}
    \usetikzlibrary{shapes,arrows}
    \usetikzlibrary{arrows,calc,positioning}

    \tikzset{
        block/.style = {draw, rectangle,
            minimum height=1cm,
            minimum width=1.5cm},
        input/.style = {coordinate,node distance=1cm},
        output/.style = {coordinate,node distance=4cm},
        arrow/.style={draw, -latex,node distance=2cm},
        pinstyle/.style = {pin edge={latex-, black,node distance=2cm}},
        sum/.style = {draw, circle, node distance=1cm},
    }
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
    
\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\newenvironment{problem}[2][Problem]
    { \begin{mdframed}[backgroundcolor=gray!20] \textbf{#1 #2} \\}
    {  \end{mdframed}}

% Define solution environment
\newenvironment{solution}
    {\textit{Solution:}}
    {}

\renewcommand{\qed}{\quad\qedsymbol}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%Header-Make sure you update this information!!!!
\noindent
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\large\textbf{XXX} \hfill \textbf{Homework - 4}   \\
Email: XXX \hfill ID: XXX \\
\normalsize Course: Bayesian \hfill Term: Spring 2020\\
Instructor: Dr. Luo  \hfill Due Date: $16^{th}$ Mar., 2020 \\
\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{7.2}
Unit information prior: Letting $\Psi=\Sigma^{-1},$ show that a unit information prior for $(\boldsymbol{\theta}, \Psi)$ is given by $\boldsymbol{\theta} | \Psi \sim$ multivariate normal $\left(\overline{\boldsymbol{y}}, \Psi^{-1}\right)$ and $\Psi \sim$ Wishart $\left(p+1, \mathbf{S}^{-1}\right),$ where $\mathbf{S}=\sum\left(\boldsymbol{y}_{i}-\overline{\boldsymbol{y}}\right)\left(\boldsymbol{y}_{i}-\overline{\boldsymbol{y}}\right)^{T} / n .$ This can be done by mimicking the procedure outlined in Exercise 5.6 as follows: \\
a) Reparameterize the multivariate normal model in terms of the precision matrix $\Psi=\Sigma^{-1} .$ Write out the resulting log likelihood, and find a probability density $p_{U}(\boldsymbol{\theta}, \Psi)=p_{U}(\boldsymbol{\theta} | \Psi) p_{U}(\Psi)$ such that
$\log p(\boldsymbol{\theta}, \Psi)=l(\boldsymbol{\theta}, \Psi | \mathbf{Y}) / n+c,$ where $c$ does not depend on $\boldsymbol{\theta}$ or $\Psi$
Hint: Write $\left(\boldsymbol{y}_{i}-\boldsymbol{\theta}\right)$ as $\left(\boldsymbol{y}_{i}-\overline{\boldsymbol{y}}+\overline{\boldsymbol{y}}-\boldsymbol{\theta}\right),$ and note that $\sum \boldsymbol{a}_{i}^{T} \mathbf{B} \boldsymbol{a}_{i}$ can
be written as $\operatorname{tr}(\mathbf{A B}),$ where $\mathbf{A}=\sum \boldsymbol{a}_{i} \boldsymbol{a}_{i}^{T}$.\\
b) Let $p_{U}(\Sigma)$ be the inverse-Wishart density induced by $p_{U}(\Psi)$. Obtain a density $p_{U}\left(\boldsymbol{\theta}, \Sigma | \boldsymbol{y}_{1}, \ldots, \boldsymbol{y}_{n}\right) \propto p_{U}(\boldsymbol{\theta} | \Sigma) p_{U}(\boldsymbol{\Sigma}) p\left(\boldsymbol{y}_{1}, \ldots, \boldsymbol{y}_{n} | \boldsymbol{\theta}, \Sigma\right) .$ Can
this be interpreted as a posterior distribution for $\theta$ and $\Sigma ?$ 
\end{problem}
\begin{solution}



\end{solution} 

\noindent\rule{7in}{2.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{7.6}
Diabetes data: A population of 532 women living near Phoenix, Arizona were tested for diabetes. Other information was gathered from these women at the time of testing, including number of pregnancies, glucose level, blood pressure, skin fold thickness, body mass index, diabetes pedigree and age. This information appears in the file azdiabetes. dat. Model the joint distribution of these variables for the diabetics and non-diabetics separately, using a multivariate normal distribution:\\
a) For both groups separately, use the following type of unit information prior, where $\hat{\Sigma}$ is the sample covariance matrix.\\
i. $\boldsymbol{\mu}_{0}=\overline{\boldsymbol{y}}, \Lambda_{0}=\hat{\Sigma}$\\
ii. $\mathbf{S}_{0}=\hat{\Sigma}, \nu_{0}=p+2=9$\\
Generate at least $10,000$ Monte Carlo samples for $\left\{\boldsymbol{\theta}_{d}, \Sigma_{d}\right\}$ and $\left\{\boldsymbol{\theta}_{n}, \Sigma_{n}\right\},$ the model parameters for diabetics and non-diabetics respectively. For each of the seven variables $j \in\{1, \ldots, 7\},$ compare the marginal posterior distributions of $\theta_{d, j}$ and $\theta_{n, j} .$ Which variables seem
to differ between the two groups? Also obtain $\operatorname{Pr}\left(\theta_{d, j}>\theta_{n, j} | \mathbf{Y}\right)$ for each $j \in\{1, \ldots, 7\}$.\\
b) Obtain the posterior means of $\Sigma_{d}$ and $\Sigma_{n},$ and plot the entries versus each other. What are the main differences, if any?

\end{problem}
\begin{solution}


\end{solution} 

\noindent\rule{7in}{2.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{8.3}
Hierarchical modeling: The files school1. dat through school8. dat give weekly hours spent on homework for students sampled from eight different schools. Obtain posterior distributions for the true means for the eight different schools using a hierarchical normal model with the following prior parameters:
$$
\mu_{0}=7, \gamma_{0}^{2}=5, \quad \tau_{0}^{2}=10, \eta_{0}=2, \quad \sigma_{0}^{2}=15, \nu_{0}=2
$$
a) Run a Gibbs sampling algorithm to approximate the posterior distribution of $\left\{\boldsymbol{\theta}, \sigma^{2}, \mu, \tau^{2}\right\} .$ Assess the convergence of the Markov chain, and find the effective sample size for $\left\{\sigma^{2}, \mu, \tau^{2}\right\} .$ Run the chain long enough so that the effective sample sizes are all above $1,000$.\\
b) Compute posterior means and $95 \%$ confidence regions for $\left\{\sigma^{2}, \mu, \tau^{2}\right\}$ Also, compare the posterior densities to the prior densities, and discuss what was learned from the data.\\
c) Plot the posterior density of $R=\frac{\tau^{2}}{\sigma^{2}+\tau^{2}}$ and compare it to a plot of the prior density of $R .$ Describe the evidence for between-school variation.\\
d) Obtain the posterior probability that $\theta_{7}$ is smaller than $\theta_{6},$ as well as the posterior probability that $\theta_{7}$ is the smallest of all the $\theta$ 's.\\
e) Plot the sample averages $\bar{y}_{1}, \ldots, \bar{y}_{8}$ against the posterior expectations of $\theta_{1}, \ldots, \theta_{8},$ and describe the relationship. Also compute the sample mean of all observations and compare it to the posterior mean of $\mu$.

\end{problem}
\begin{solution}



\end{solution} 
\noindent\rule{7in}{2.8pt}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}