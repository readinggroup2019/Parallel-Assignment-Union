\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text. 
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage[fleqn]{amsmath}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{verbatim}
\usepackage[numbered]{mcode}
\usepackage{float}
\usepackage{tikz}
    \usetikzlibrary{shapes,arrows}
    \usetikzlibrary{arrows,calc,positioning}

    \tikzset{
        block/.style = {draw, rectangle,
            minimum height=1cm,
            minimum width=1.5cm},
        input/.style = {coordinate,node distance=1cm},
        output/.style = {coordinate,node distance=4cm},
        arrow/.style={draw, -latex,node distance=2cm},
        pinstyle/.style = {pin edge={latex-, black,node distance=2cm}},
        sum/.style = {draw, circle, node distance=1cm},
    }
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
    
\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\newenvironment{problem}[2][Problem]
    { \begin{mdframed}[backgroundcolor=gray!20] \textbf{#1 #2} \\}
    {  \end{mdframed}}

% Define solution environment
\newenvironment{solution}
    {\textit{Solution:}}
    {}

\renewcommand{\qed}{\quad\qedsymbol}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%Header-Make sure you update this information!!!!
\noindent
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\large\textbf{hhhhhhh} \hfill \textbf{Homework - 3}   \\
Email: ????? \hfill ID:2014053 \\
\normalsize Course:Linear model \hfill Term: Spring 2020\\
Instructor: Dr. He \hfill Due Date: $8^{th}$ Mar., 2020 \\
\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{4.2}
 Under the Gauss-Markov model, show that for \(\lambda\) such that \(\lambda^{T}\) b is estimable,
\(\operatorname{Var}\left(\lambda^{T} \hat{\mathbf{b}}\right)=\sigma^{2} \lambda^{T}\left(\mathbf{X}^{T} \mathbf{X}\right)^{g} \lambda\) does not depend on the choice of generalized
inverse \(\left(\mathbf{X}^{T} \mathbf{X}\right)^{g} .\)

\end{problem}
\begin{solution}

\end{solution} 
\noindent\rule{7in}{2.8pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{4.6}
Suppose we have the simple linear regression model \(y_{i}=\beta_{0}+\beta_{1} x_{i}+e_{i}, i=1, \ldots, N\) where \(e_{i}\) are uncorrelated and \(\operatorname{Var}\left(e_{i}\right)=\sigma^{2} .\) Consider the instrumental variables estimator of the slope \(\tilde{b}_{1}=\sum_{i=1}^{N}\left(z_{i}-\bar{z}\right)\left(y_{i}-\bar{y}\right) / \sum_{i=1}^{N}\left(z_{i}-\bar{z}\right)\left(x_{i}-\bar{x}\right)\) where \(z_{1}, \ldots, z_{N}\) are known constants.

a. Is \(\tilde{b}_{1}\) an unbiased estimator of the slope parameter \(\beta_{1} ?\)

b. Find the variance of \(\tilde{b}_{1}\).

c. We know that taking \(z_{i}=x_{i}\) gives our familiar least squares estimator
\(\hat{b}_{1} .\) Find the ratio of the two variances, \(\operatorname{Var}\left(\hat{b}_{1}\right) / \operatorname{Var}\left(\tilde{b}_{1}\right),\) and show that
it is less than or equal to 1 ($\hat{b}_{1}$ is BLUE).


You may find the following results useful:

\(\sum_{i=1}\left(x_{i}-\bar{x}\right)=\sum_{i=1}\left(z_{i}-\bar{z}\right)=0\)
and \(\sum_{i=1}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)=\sum_{i=1}\left(x_{i}-\bar{x}\right) y_{i}=\sum_{i=1} x_{i}\left(y_{i}-\bar{y}\right)\).


\end{problem}
\begin{solution}

\end{solution} 

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{4.12}
Prove the Gauss-Markov Theorem directly, that is, by constructing all linear
estimators  \(\mathbf{a}^{T} \mathbf{y}\) that are unbiased for \(\lambda^{T} \mathbf{b}\) (find a family of solutions $\mathbf{a}(\mathbf{z})$), and
then minimizing the variance \(\sigma^{2} \mathbf{a}^{T} \mathbf{a}\).

\end{problem}
\begin{solution}

\end{solution} 

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{4.20}
Under Gauss-Markov assumptions, show that if \(\operatorname{Cov}\left(\mathbf{a}^{T} \mathbf{y}, \mathbf{d}^{T} \hat{\mathbf{e}}\right)=0\) for all \(\mathbf{d}\),
then \(\mathbf{a}^{T} \mathbf{y}\) is the BLUE for its expectation.

\end{problem}
\begin{solution}

\end{solution} 

\noindent\rule{7in}{2.8pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
 